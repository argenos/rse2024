<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Program | RSE'23</title>
</head>

<body>

   <div class="banner">
        <img src="assets/kcl.jpg" alt="Conference Template Banner">
        <div class="top-left">
            <span class="title1">Robotics</span><span class="title2">SoftwareEngineering</span> <span class="year">2023</span>
        </div>
        <div class="bottom-right">
            September 4-7, 2023 <br> King's College London, United Kingdom
        </div>
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a title="Conference Home Page" href=".">Home</a>
            </td>
            <!-- <td class="navigation">
                <a title="Register for the Conference" href="registration">Registration</a>
            </td> --> 
             <td class="navigation">
                <a class="current" title="Conference Program" href="program">Program</a> 
            </td>
            <td class="navigation">
                <a title="Directions to the Conference" href="directions">Directions</a>
            </td>
            <!--<td class="navigation">
                <a title="Conference Flyer" href="flyer">Flyer</a>
            </td>-->
        </tr>
    </table>

    <h2>Tentative program </h2>
    <p>
       
       <!-- <img class="center" src="assets/Program.png" alt="Main program" id="mp">-->
        
    </p>
    
    <p>
       
    <h2>The Talks</h2>
    
    <p>

        Presentation should be confined to <b>10 minutes (approx.)</b> followed by 15 minutes of discussion.

    </p>
    
    
    <h2>Schedule</h2>
    <h4>Monday, September 4</h4>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                12:00 - 13:30
            </td>
            <td class="title-special">
                Arrival, registration and lunch
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                13:30-15:00
            </td>
            <td class="title-special">
                Session 1: Model-Based Engineering
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: Luciana Rebelo
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:30 - 13:55
            </td>
            <td class="title">
                Co-verification for robotics: from simulation to verification of hybrid systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Pedro Ribeiro  (University of York, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Robots are expected to play important roles in furthering prosperity, however providing formal guarantees on their (safe) behaviour is not yet fully within grasp given the multifaceted nature of such cyber-physical systems. Simulation, favoured by practitioners, provides an avenue for experimenting with different scenarios before committing to expensive tests and proofs. In this talk, I will discuss how models may be brought together for (co-)verification of system properties, with simulation complementing verification. This will be cast using the model-driven RoboStar framework, that clearly identifies models of the software, hardware, and scenario, and has heterogeneous formal semantics amenable to verification using state-of-the-art model-checkers and theorem provers, such as Isabelle/UTP.    
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:55 - 14:20
            </td>
            <td class="title">
                Specification and Task Scheduling of Mission Tasks for Heterogeneous Robot Systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Gricel Vazquez Flores (University of York, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                The specification of mission requirements for multi-robot systems poses a set of challenges since they consider multiple spatial and time constraints, and optimal objectives, such as minimizing the battery consumption while maximizing the probability of mission success. To ease the formalization of requirements and avoid unambiguity, we present QUARTET, a catalogue of robotic mission specifications in probabilistic temporal logic. Moreover, we introduce a formal tasK AllocatioN and scheduling apprOAch for multi-robot missions (KANOA). KANOA handles the allocation of the mission tasks to robots to mitigate the complexity of robotic mission planning, and the scheduling of the allocated tasks separately. To that end, the task allocation problem is formalized in first-order logic and resolved using the Alloy model analyzer, and the task scheduling problem is encoded as a Markov decision process and resolved using the PRISM probabilistic model checker.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:20 - 14:45
            </td>
            <td class="title">
                Runtime Monitoring of Robotic Applications
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Sven Peldszus (Ruhr University Bochum, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                In my talk, I will present how to trace non-functional properties throughout the development process of robotic applications to monitor and verify these at runtime.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:45 - 15:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            
    </table>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                15:00 - 15:30
            </td>
            <td class="title-special">
                Coffee/Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                15:30-17:00
            </td>
            <td class="title-special">
                Session 2: Testing
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: Luciana Rebelo
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                15:30-15:55
            </td>
            <td class="title">
                A Study in Software Testing for Robotics
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Argentina Ortega (Hochschule Bonn-Rhein-Sieg and Ruhr University Bochum, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
              </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                15:55 - 16:20
            </td>
            <td class="title">
                A Framework for Test Model Refinement
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Hugo Araujo (King's College London, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Model-based testing (MBT) is a testing method that employs (mathematical) models of a system under test (SUT) in order to generate test cases. Choosing the right level of abstraction for the test model is crucial to the success of a model-based testing strategy. We argue that the level of abstraction in models impacts the strategy's effectiveness and precision. In order to investigate our hypothesis, we conducts an experiment that employs several distinct test models that have been developed using our process for step-wise enrichment of test models for robots and autonomous systems (RAS). It is intended as a step towards guidelines for those who build behaviour models for the purpose of testing.
            </td>
        </tr>
    </table>
    
    
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                16:20 - 16:45
            </td>
            <td class="title">
                Conformance Testing for Trustworthy Autonomous Systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Mohammad Mousavi (King's College London, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                16:45 - 17:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            <td class="speaker">
                
            </td>
        </tr>
        <tr>
            <td class="abstract">
           </td>
        </tr>
    </table>
    
    
    <h4>Tuesday, September 5</h4>
    
    
    
    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                09:00 - 10:00 

            </td>
            <td class="title">
                Keynote:  What Should I Verify?

            </td>
        </tr>
        <tr>
            <td class="speaker">
                Marie Farell (University of Manchester, UK)

            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: Pedro Ribeiro
            </td>
        </tr>
    </table>

    
    <table>
        <tr>
            <td class="date" rowspan="2">
                10:00 - 10:30
            </td>
            <td class="title-special">
                Coffee/Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                10:30 - 12:00
            </td>
            <td class="title-special">
                Session 3:  Adaptation and Human-Robot Interactions
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>
    

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:30 - 10:55
            </td>
            <td class="title">
                Model-Driven Software Composition as Enabler for Cognitive Robotic Systems 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Christian Schlegel (Technische Hochschule Ulm, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Robots are the promise of being universal machines: flexible and versatile in use, independent in fulfilling tasks, easily adaptable to new tasks, and even being able to select on their own those skills which are best suited to fulfill assigned jobs in an adequate manner. This comes with a tremendous complexity of their software systems, the need for introspection by the robot itself and the need for a semantic interaction between the user and the robot. A model-driven approach for robotic software systems based on service-oriented components following the principles of separation of roles and of composition already proved to be successful in (a) reducing the overall effort of composing and modifying complex robotics software systems, (b) matching task-level plots with available skills, and (c) using intuitive graphical representations for a semantic configuration (e.g., place a 4-way-stop policy for robots at a crossing). A core asset are the so-called digital data sheets which describe the various building blocks (software components, skills, task plots etc.) as blocks with ports and from an outside view. Digital data sheets are abstracted representation which are not suitable to generate a building block but they inform the user about what are the required and provided ports of the asset, what kind of operating modes it possesses, what are its configurations and their impacts on its behavior and qualities, etc. Digital data sheets are directly derived from the workflow in the model-driven toolchain.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:55 - 11:20
            </td>
            <td class="title">
                Humans versus Machines: The Battle for Supporting Cyber­-Physical Systems Design 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Claudio Menghi (University of Bergamo, Italy)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Developing robotics and cyber­-physical systems requires engineers to detect and fix design flaws before their deployment. This activity is complex, error-prone, and expensive. Engineers often rely on machines for support in system design since, unlike humans, they can perform massive computations in a limited time. However, machines do not possess the reasoning capabilities typical of humans. This talk will reflect on the "Humans versus Machines" dilemma. It will argue that developing effective techniques that combine human and machine capabilities is necessary to support the design of robotics and cyber­-physical systems applications of the future. The talk will present recent techniques that rely on this idea, discuss results, and describe lessons learned.
           </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:20 - 11:45
            </td>
            <td class="title">
                Towards Adaptive Planning of Assistive-care Robot Tasks 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Ioannis Stefanakos (University of York, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                I will present an adaptive path planning framework for robotic mission execution in assistive-care applications. The framework provides a graph-based environment modelling approach, with dynamic path finding performed using Dijkstra’s algorithm. A predictive module is used to estimate the human’s movement through the environment, allowing replanning of the robot’s path. I will demonstrate the use of the framework in a simulated assistive-care case study in which a mobile robot navigates through the environment and monitors an end user with mild physical or cognitive impairments.
             </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:45 - 12:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            <td class="speaker">
                
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>
    
 
    <table>
        <tr>
            <td class="date" rowspan="2">
                12:00 - 13:30
            </td>
            <td class="title-special">
                Lunch
            </td>
        </tr>
        <tr>
            <td class="abstract">
             
            </td>
        </tr>
    </table>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                13:30 - 15:00
            </td>
            <td class="title-special">
                Session  4: Domain Engineering and Variability
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: Thorsten Berger
            </td>
        </tr>
    </table>
    
 
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:30 - 13:55
            </td>
            <td class="title">
                On Modelling and Analysing Autonomous Underwater Robots as Probabilistic Featured Transition Systems 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Juliane Päßler (University of Oslo, Norway)
            </td>
        </tr>
        <tr>
            <td class="abstract">
             </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:55 - 14:20
            </td>
            <td class="title">
                Exploring the Architecture and Development Process of Open-Source ML-Enabled Software Systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Yorick Sens (Ruhr University Bochum, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:20 - 14:45
            </td>
            <td class="title">
                Tracing Security Features in Robotic Systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Kevin Hermann (Ruhr University Bochum, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Maintaining security features is crucial for any robotic system especially if a security incident occured. Once a security breach is detected, it is important to quickly provide a fix to avoid damage or costs. To this end, developers need to find vulnerable code within the system as fast as possible. For that tracing links can be leveraged to locate the corresponding code fragments of affected security features. In my presentation, I talk about methods and the importance of tracing security features in robotic systems.
            </td>
        </tr>
    </table>   

      <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:45 - 15:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            <td class="speaker">
                
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table> 

    
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                15:00 - 15:30
            </td>
            <td class="title-special">
                Coffee/Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                15:30 - 17:00
            </td>
            <td class="title-special">
                Session 5: Formal Methods for Robotics
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: Marie Farrell
            </td>
        </tr>
    </table>
    
 
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                15:30 - 15:55
            </td>
            <td class="title">
                Mapping Properties of Control Theory to Software Engineering Properties with TCTL and Property Specification Pattern
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Nils Chur (Ruhr University Bochum, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Nowadays, self-adaptive software is becoming increasingly popular, with many implementations relying on embedded controls and feedback loops. Verifying that these systems are functionally correct is an essential part of the verification process, which is traditionally done through intensive simulation-based testing using test cases. However, properties such as stability and performance of the system are often difficult to prove analytically, which is why formal verification methods are used. Since control theory (CT) provides a well-established theoretical background for designing feedback loops and guarantees certain properties, it has received more attention. Until now, it has been an open research topic how software engineering (SE) approaches for self-adaptive software take into account control-theoretic properties; therefore, most control-theoretic software implementations lack a theoretical background. The formulation of these properties in a language understandable to model checkers and mapping these properties to both worlds is a challenging task. To address this challenge, this thesis deals with mapping control theoretical properties into a formal language with the help of the Property Specification Pattern (PSP). We take a bottom-up approach, defining a control design (in Simulink) for an adaptive cruise control, which is then transferred to code (C). Next, we define properties using PSP, which allow us to show whether the CT properties still hold at the code level. And finally, we provide evidence that these properties are fulfilled by the system with the UPPAAL model checker. The specified properties are intended to provide reusable patterns that can be used for similar applications.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                15:55 - 16:20
            </td>
            <td class="title">
                On Behavioural Types for Robotic Systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Emilio Tuosto (Gran Sasso Science Institute, Italy)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                The talk will review some recent proposals advocating behavioural types for the modelling, analysis, and verification of robotic applications. The aim is to identify opportunities to further refine and extend the behavioural type systems and possibly integrated them into wider contexts.
           </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                16:20 - 16:45
            </td>
            <td class="title">
                Review on Architectures in the Space Domain to support AI and DevOps: Midterm Findings

            </td>
        </tr>
        <tr>
            <td class="speaker">
                Luciana Rebelo (Gran Sasso Science Institute, Italy)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                In this study, we aim at surveying the state of the art in electrical, hardware, and software architectures in the space domain able to support Artifical Intelligence (AI) and/or promote DevOps, i.e. the Continuous Integration and Deployment (CI/CD). We are specifically interested in the use of AI on board of space devices and on solutions enabling the development of in-orbit frameworks with DevOps technologies that allow the development, testing, and deployment of flight software even when the software platform is in orbit. Aspects such as key architecture solutions, developed techniques/methods, experiments, analytical and simulation results, and challenges related to the peculiarities of space domain are investigated.
            </td>
        </tr>
    </table>


  

    <table>
        <tr>
            <td class="date" rowspan="2">
                17:00  -
            </td>
            <td class="title-special">
                Social event (walk to Westminster, riding the London Eye) 
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>
    
    <h4>Wednesday, September 6</h4>

    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                09:00 - 10:00 

            </td>
            <td class="title">
                Keynote: Learning in RoboStar
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Ana Cavalcanti (University of York, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                The RoboStar framework for Software Engineering for Robotics includes a collection of domain-specific notations to model various artefacts, and techniques for model-transformation, simulation, testing, and proof. In this presentation, we give an overview of the RoboStar approach, and focus on our support for automated testing.  It covers techniques for automatic generation of software tests, both for reactive systems, and for cyclic systems (simulations and code that uses a cyclic executive).  We explain the techniques for fault-based testing and test conversion, which ensures traceability. 
            </td>
        </tr>
    </table>

    
    <table>
        <tr>
            <td class="date" rowspan="2">
                10:00 - 10:30
            </td>
            <td class="title-special">
                Coffee/Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>

    
    <table>
        <tr>
            <td class="date" rowspan="2">
                10:30 - 12:00
            </td>
            <td class="title-special">
                Session 6: Testing and Verification

            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>
    
 
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:30 - 10:55
            </td>
            <td class="title">
                Building Digital Twins for Robots
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Mirgita Frasheri (Aarhus University, Denmark)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:55 - 11:20
            </td>
            <td class="title">
                Neural Radiance Fields for Testing Vision Components in Autonomous Underwater Vehicles
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Laura Weihl (IT University of Copenhagen, Denmark)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Navigation for autonomous underwater vehicles (AUVs) is challenging. If underwater visibility permits, incorporating input from onboard cameras into the robotic navigation stack can provide a rich source of information to navigate small GPS-denied environments. Testing vision algorithms for navigation is traditionally facilitated in simulation. However, simulators are fundamentally limited by the skill and domain knowledge of the engineers, and, specifically in the underwater setting, fail to model the long-tail of safety critical scenarios. To generate realistic test data for AUV vision components I train Neural Radiance Fields on video data of small underwater environments. Incorporating NeRFs into systematic testing procedures can address challenges of AUV navigation for safety-critical missions.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:20 - 11:45
            </td>
            <td class="title">
                How to Specify Properties of Probabilistic RoboChart Models
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Jim Woodcock (University of York, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                RoboChart is a core notation in the RoboStar framework that brings modern modelling and formal verification technologies to software engineering for robotics. It is a timed, probabilistic domain-specific language and provides a UML-like architectural and state machine modelling. This work presents RoboCertProb for specifying quantitative properties of probabilistic robotic systems modelled in RoboChart. RoboCertProb is the probabilistic extension of RoboCert, a property specification for robotics. RoboCertProb is based on PCTL* and is a subset of the discrete-time part of the Prism property language with extensions to support RoboChart. In addition to property specification, RoboCertProb configures loose constants and uninterpreted functions and operations in RoboChart models. It lets us set up environmental inputs to verify reactive probabilistic systems not directly supported in Prism with its closed-world assumption. The grammar of RoboCertProb is flexible. We implement RoboCertProb in RoboTool for specifying properties and automatically generating Prism properties. We have used it to analyse the behaviour of software controllers for two real-world robots: an industrial painting robot and an agricultural robot for treating plants with UV lights.

            </td>
        </tr>
    </table>  

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:45 - 12:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            <td class="speaker">
              
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table> 

    
    <table>
        <tr>
            <td class="date" rowspan="2">
                12:00 - 13:30
            </td>
            <td class="title-special">
                Lunch
            </td>
        </tr>
        <tr>
            <td class="abstract">
             
            </td>
        </tr>
    </table>
    
     <table>
        <tr>
            <td class="date" rowspan="2">
                13:30 - 15:00 
            </td>
            <td class="title-special">
                Session 7: Robotic Applications
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: Claudio Menghi
            </td>
        </tr>
    </table>
    
 
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:30 - 13:55
            </td>
            <td class="title">
                From chaos to structure: Unifying software architecture of robots 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Lenka Mudrich (University of Leeds, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                In the rapidly evolving field of robotics, software architecture plays a pivotal role in enabling intelligent behaviour and efficient operation. However, the increasing complexity and heterogeneity of robot systems have led to a proliferation of diverse software architectures, resulting in fragmented development processes and limited interoperability. This talk aims to explore the critical need for software architecture unification in the realm of robotics. I will explore the concept of software architecture unification, which seeks to establish a common framework and set of principles for designing and implementing software architectures in robots. Furthermore, I will discuss the role of modularisation, standardisation, and open-source initiatives in fostering a unified ecosystem. Overall, this talk aims to shed light on the importance of software architecture unification for robots, exploring its benefits, challenges, and potential solutions. By embracing a unified approach, the robotics community can propel the field forward, enabling faster innovation, wider adoption, and more robust and versatile robot systems. 
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:55 - 14:20
            </td>
            <td class="title">
                Runtime reconfiguration of robot control systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Davide Brugali (University of Bergamo, Italy)
            </td>
        </tr>
        <tr>
            <td class="abstract">
             </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:20 - 14:45
            </td>
            <td class="title">
                Imitation Learning for creating 3D twin models using a manipulator robot arm
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Juan Antonio Pinera Garcia (Gran Sasso Science Institute, Italy)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Obtaining a precise description of the materials used in ancient art works has proven to be a challenging task, and while progress has been made in employing X-Ray technology to create detailed twin models of two dimensional paintings, 3D objects remain a considerable challenge. This work describes the idea of using Imitation Learning techniques to allow a Human-In-The-Loop algorithm to create high precision models of three dimensional art works. Although the technology exists to be able to determine with high precision the atomic composition of very small segments of an object, the algorithm must automatically detect the different object shapes and perform efficient motion planning in order to cover the object entirely at a desirable distance.

            </td>
        </tr>
    </table>      
    

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:45 - 15:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            <td class="speaker">
               
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

   <table>
        <tr>
            <td class="date" rowspan="2">
                15:00 - 15:30
            </td>
            <td class="title-special">
                Coffee/Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>

    
    <table>
        <tr>
            <td class="date" rowspan="2">
                15:30 - 17:00
            </td>
            <td class="title-special">
                Break-out discussions, planning collaboration
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                18:30 
            </td>
            <td class="title-special">
                Dinner
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>
    
    <h4>Thursday, September 7</h4>

    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                09:00 - 10:00 

            </td>
            <td class="title">
                Causal Temporal Reasoning for Markov Decision Processes
            </td>
        </tr>
        <tr>
            <td class="speaker">
               Nicola Paoletti (King's College London, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                10:00 - 10:30
            </td>
            <td class="title-special">
                Coffee/Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>

    
    <table>
        <tr>
            <td class="date" rowspan="2">
                10:30 - 12:30
            </td>
            <td class="title-special">
                Session 8: Robotic Applications
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>
    
 
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:30 - 10:55
            </td>
            <td class="title">
                 Ethical-aware robots 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Patrizio Pelliccione (Gran Sasso Science Institute, Italy)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:55 - 11:20
            </td>
            <td class="title">
                Enabling Adaptation at Runtime: A Knowledge-Based Framework for Task and Architecture Co-Adaptation in Autonomous Robots
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Gustavo Rezende Silva (TU Delft, The Netherlands)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                While operating, robots are subject to uncertainties, both from internal system factors (e.g., sensor failures) and external environment variables (e.g., different terrains). To overcome uncertainties, robots must be able to adapt at runtime their mission execution (e.g., change task being performed) and their software architecture (e.g., deactivate and activate software components). This presentation introduces a knowledge-based self-adaptation framework designed to enable robots to adapt their mission and architecture at runtime. The proposed framework builds upon the Metacontrol framework, offering a novel contribution in the form of a new metamodel for the knowledge base. The proposed metamodel aims to capture essential information about the robotic system's architecture, encompassing all available configuration variants, relationships and constraints among configurations, attributes of the system and environment, and interdependencies between the robots' tasks and configurations. The metamodel is modeled as a hypergraph, enabling a more intuitive representation of the relationship. To guide the design phase and enable evaluation, we defined a set of requirements for robotic self-adaptive systems. Then, in the evaluation step, we verify if the framework fulfills the defined requirements, and use this assessment as criteria for comparing our approach against other existing self-adaptation frameworks. Furthermore, we showcase the applicability of our framework through its implementation and application to a use case involving an underwater robot deployed for pipeline inspection.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:20 - 11:45
            </td>
            <td class="title">
                Teaching autonomous vehicle engineering 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Thorsten Berger (Ruhr University Bochum, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>  

    
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:45 - 12:10
            </td>
            <td class="title">
                Robotics Software Engineering in the SESAME H2020 Project
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Simos Gerasimou (University of York, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Within the European project SESAME, we develop a model-based approach supporting the systematic engineering of dependable learning-enabled robotic systems. In this talk, we will overview recent advances made by the project team to provide assurances for the trustworthy, robust and explainable operation of robotic systems, focusing particularly on techniques for testing the robotics and their AI-based components. The talk will be complemented by an overview of the diverse SESAME use cases from the domains of healthcare, manufacturing, agriculture and emergency response.
            </td>
        </tr>
    </table> 

    
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                12:10 - 12:30
            </td>
            <td class="title">
                Discussion and Closing
            </td>
        </tr>
        <tr>
            <td class="speaker">
              
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                12:30 - 14:00
            </td>
            <td class="title-special">
                Lunch
            </td>
        </tr>
        <tr>
            <td class="abstract">
             
            </td>
        </tr>
    </table>
 
 <footer>
        &copy; Conference Organizers
        &nbsp;|&nbsp; Design by <a href="https://github.com/mikepierce">Mike Pierce</a>
    </footer>

</body>
</html>

