<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Program | RSE'23</title>
</head>

<body>

   <div class="banner">
        <img src="assets/kcl.jpg" alt="Conference Template Banner">
        <div class="top-left">
            <span class="title1">Robotics</span><span class="title2">SoftwareEngineering</span> <span class="year">2023</span>
        </div>
        <div class="bottom-right">
            September 4-7, 2023 <br> King's College London, United Kingdom
        </div>
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a title="Conference Home Page" href=".">Home</a>
            </td>
            <!-- <td class="navigation">
                <a title="Register for the Conference" href="registration">Registration</a>
            </td> --> 
             <td class="navigation">
                <a class="current" title="Conference Program" href="program">Program</a> 
            </td>
            <td class="navigation">
                <a title="Directions to the Conference" href="directions">Directions</a>
            </td>
            <!--<td class="navigation">
                <a title="Conference Flyer" href="flyer">Flyer</a>
            </td>-->
        </tr>
    </table>

    <h2>Tentative program </h2>
    <p>
       
       <!-- <img class="center" src="assets/Program.png" alt="Main program" id="mp">-->
        
    </p>
    
    <p>
       
    <h2>The Talks</h2>
    
    <p>

        Presentation should be confined to <b>10 minutes (approx.)</b> followed by 15 minutes of discussion.

    </p>
    
    
    <h2>Schedule</h2>
    <h4>Monday, September 4</h4>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                12:00 - 13:30
            </td>
            <td class="title-special">
                Arrival, registration and lunch
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                13:30-15:00
            </td>
            <td class="title-special">
                Session 1: Model-Based Engineering
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:30 - 13:55
            </td>
            <td class="title">
                Co-verification for robotics: from simulation to verification of hybrid systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Pedro Ribeiro  (University of York, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Robots are expected to play important roles in furthering prosperity, however providing formal guarantees on their (safe) behaviour is not yet fully within grasp given the multifaceted nature of such cyber-physical systems. Simulation, favoured by practitioners, provides an avenue for experimenting with different scenarios before committing to expensive tests and proofs. In this talk, I will discuss how models may be brought together for (co-)verification of system properties, with simulation complementing verification. This will be cast using the model-driven RoboStar framework, that clearly identifies models of the software, hardware, and scenario, and has heterogeneous formal semantics amenable to verification using state-of-the-art model-checkers and theorem provers, such as Isabelle/UTP.    
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:55 - 14:20
            </td>
            <td class="title">
                Specification and Task Scheduling of Mission Tasks for Heterogeneous Robot Systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Gricel Vazquez Flores (University of York, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!--During the last two decades, service choreography has been receiving considerable attention by the research community as a versatile approach for building service-based distributed systems. In business computing, service choreography is a form of service composition in which the interaction protocol among software services is defined from a global perspective. By embracing the main characteristic of distributed systems, the idea underlying the notion of service choreography can be summarised as follows: "dancers dance following a global scenario without a single point of control".-->
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:20 - 14:45
            </td>
            <td class="title">
                Runtime Monitoring of Robotic Applications
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Sven Peldszus (Ruhr University Bochum, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!--During the last two decades, service choreography has been receiving considerable attention by the research community as a versatile approach for building service-based distributed systems. In business computing, service choreography is a form of service composition in which the interaction protocol among software services is defined from a global perspective. By embracing the main characteristic of distributed systems, the idea underlying the notion of service choreography can be summarised as follows: "dancers dance following a global scenario without a single point of control".-->
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:45 - 15:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            
    </table>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                15:00 - 15:30
            </td>
            <td class="title-special">
                Coffee/Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                15:30-17:00
            </td>
            <td class="title-special">
                Session 2: Testing
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                15:30-15:55
            </td>
            <td class="title">
                A Study in Software Testing for Robotics
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Argentina Ortega (Hochschule Bonn-Rhein-Sieg and Ruhr University Bochum, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
              </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                15:55 - 16:20
            </td>
            <td class="title">
                A Framework for Test Model Refinement
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Hugo Araujo (King's College London, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Model-based testing (MBT) is a testing method that employs (mathematical) models of a system under test (SUT) in order to generate test cases. Choosing the right level of abstraction for the test model is crucial to the success of a model-based testing strategy. We argue that the level of abstraction in models impacts the strategy's effectiveness and precision. In order to investigate our hypothesis, we conducts an experiment that employs several distinct test models that have been developed using our process for step-wise enrichment of test models for robots and autonomous systems (RAS). It is intended as a step towards guidelines for those who build behaviour models for the purpose of testing.
            </td>
        </tr>
    </table>
    
    
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                16:20 - 16:45
            </td>
            <td class="title">
                What Should I Verify?
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Marie Farell (University of Manchester, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                16:45 - 17:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            <td class="speaker">
                
            </td>
        </tr>
        <tr>
            <td class="abstract">
           </td>
        </tr>
    </table>
    
    
    <h4>Tuesday, September 5</h4>
    
    
    
    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                09:00 - 10:00 

            </td>
            <td class="title">
                Keynote: TBA
            </td>
        </tr>
        <tr>
            <td class="speaker">
                
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>

    
    <table>
        <tr>
            <td class="date" rowspan="2">
                10:00 - 10:30
            </td>
            <td class="title-special">
                Coffee/Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                10:30 - 12:00
            </td>
            <td class="title-special">
                Session 3:  Adaptation and Human-Robot Interactions
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>
    

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:30 - 10:55
            </td>
            <td class="title">
                Model-Driven Software Composition as Enabler for Cognitive Robotic Systems 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Christian Schlegel (Technische Hochschule Ulm, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">

            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:55 - 11:20
            </td>
            <td class="title">
                Humans versus Machines: The Battle for Supporting Cyber­-Physical Systems Design 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Claudio Menghi (University of Bergamo, Italy)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Developing robotics and cyber­-physical systems requires engineers to detect and fix design flaws before their deployment. This activity is complex, error-prone, and expensive. Engineers often rely on machines for support in system design since, unlike humans, they can perform massive computations in a limited time. However, machines do not possess the reasoning capabilities typical of humans. This talk will reflect on the "Humans versus Machines" dilemma. It will argue that developing effective techniques that combine human and machine capabilities is necessary to support the design of robotics and cyber­-physical systems applications of the future. The talk will present recent techniques that rely on this idea, discuss results, and describe lessons learned.
           </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:20 - 11:45
            </td>
            <td class="title">
                Towards Adaptive Planning of Assistive-care Robot Tasks 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Ioannis Stefanakos (University of York, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
             </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:45 - 12:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            <td class="speaker">
                
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>
    
 
    <table>
        <tr>
            <td class="date" rowspan="2">
                12:00 - 13:30
            </td>
            <td class="title-special">
                Lunch
            </td>
        </tr>
        <tr>
            <td class="abstract">
             
            </td>
        </tr>
    </table>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                13:30 - 15:00
            </td>
            <td class="title-special">
                Session  4: Domain Engineering and Variability
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>
    
 
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:30 - 13:55
            </td>
            <td class="title">
                On Modelling and Analysing Autonomous Underwater Robots as Probabilistic Featured Transition Systems 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Juliane Päßler (University of Oslo, Norway)
            </td>
        </tr>
        <tr>
            <td class="abstract">
             </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:55 - 14:20
            </td>
            <td class="title">
                Exploring the Architecture and Development Process of Open-Source ML-Enabled Software Systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Yorick Sens (Ruhr University Bochum, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:20 - 14:45
            </td>
            <td class="title">
                Tracing Security Features in Robotic Systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Kevin Hermann (Ruhr University Bochum, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>   

      <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:45 - 15:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            <td class="speaker">
                
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table> 

    
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                15:00 - 15:30
            </td>
            <td class="title-special">
                Coffee/Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                15:30 - 17:00
            </td>
            <td class="title-special">
                Session 5: Formal Methods for Robotics
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>
    
 
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                15:30 - 15:55
            </td>
            <td class="title">
                Mapping Properties of Control Theory to Software Engineering Properties with TCTL and Property Specification Pattern
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Nils Chur (Ruhr University Bochum, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Nowadays, self-adaptive software is becoming increasingly popular, with many implementations relying on embedded controls and feedback loops. Verifying that these systems are functionally correct is an essential part of the verification process, which is traditionally done through intensive simulation-based testing using test cases. However, properties such as stability and performance of the system are often difficult to prove analytically, which is why formal verification methods are used. Since control theory (CT) provides a well-established theoretical background for designing feedback loops and guarantees certain properties, it has received more attention. Until now, it has been an open research topic how software engineering (SE) approaches for self-adaptive software take into account control-theoretic properties; therefore, most control-theoretic software implementations lack a theoretical background. The formulation of these properties in a language understandable to model checkers and mapping these properties to both worlds is a challenging task. To address this challenge, this thesis deals with mapping control theoretical properties into a formal language with the help of the Property Specification Pattern (PSP). We take a bottom-up approach, defining a control design (in Simulink) for an adaptive cruise control, which is then transferred to code (C). Next, we define properties using PSP, which allow us to show whether the CT properties still hold at the code level. And finally, we provide evidence that these properties are fulfilled by the system with the UPPAAL model checker. The specified properties are intended to provide reusable patterns that can be used for similar applications.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                15:55 - 16:20
            </td>
            <td class="title">
                On Behavioural Types for Robotic Systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Emilio Tuosto (Gran Sasso Science Institute, Italy)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                The talk will review some recent proposals advocating behavioural types for the modelling, analysis, and verification of robotic applications. The aim is to identify opportunities to further refine and extend the behavioural type systems and possibly integrated them into wider contexts.
           </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                16:20 - 16:45
            </td>
            <td class="title">
                How to Specify Properties of Probabilistic RoboChart Models
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Jim Woodcock (University of York, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                RoboChart is a core notation in the RoboStar framework that brings modern modelling and formal verification technologies to software engineering for robotics. It is a timed, probabilistic domain-specific language and provides a UML-like architectural and state machine modelling. This work presents RoboCertProb for specifying quantitative properties of probabilistic robotic systems modelled in RoboChart. RoboCertProb is the probabilistic extension of RoboCert, a property specification for robotics. RoboCertProb is based on PCTL* and is a subset of the discrete-time part of the Prism property language with extensions to support RoboChart. In addition to property specification, RoboCertProb configures loose constants and uninterpreted functions and operations in RoboChart models. It lets us set up environmental inputs to verify reactive probabilistic systems not directly supported in Prism with its closed-world assumption. The grammar of RoboCertProb is flexible. We implement RoboCertProb in RoboTool for specifying properties and automatically generating Prism properties. We have used it to analyse the behaviour of software controllers for two real-world robots: an industrial painting robot and an agricultural robot for treating plants with UV lights.
            </td>
        </tr>
    </table>


    
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                16:45 - 17:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            <td class="speaker">
                
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                18:00 
            </td>
            <td class="title-special">
                Social event (walk to Westminster, riding the London Eye) 
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>
    
    <h4>Wednesday, September 6</h4>

    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                09:00 - 10:00 

            </td>
            <td class="title">
                Keynote: Learning in RoboStar
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Ana Cavalcanti (University of York, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                The RoboStar framework for Software Engineering for Robotics includes a collection of domain-specific notations to model various artefacts, and techniques for model-transformation, simulation, testing, and proof. In this presentation, we give an overview of the RoboStar approach, and focus on our support for automated testing.  It covers techniques for automatic generation of software tests, both for reactive systems, and for cyclic systems (simulations and code that uses a cyclic executive).  We explain the techniques for fault-based testing and test conversion, which ensures traceability. 
            </td>
        </tr>
    </table>

    
    <table>
        <tr>
            <td class="date" rowspan="2">
                10:00 - 10:30
            </td>
            <td class="title-special">
                Coffee/Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>

    
    <table>
        <tr>
            <td class="date" rowspan="2">
                10:30 - 12:00
            </td>
            <td class="title-special">
                Session 5: Testing and Verification

            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>
    
 
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:30 - 10:55
            </td>
            <td class="title">
                Building Digital Twins for Robots
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Mirgita Frasheri (Aarhus University, Denmark)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:55 - 11:20
            </td>
            <td class="title">
                Neural Radiance Fields for Testing Vision Components in Autonomous Underwater Vehicles
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Laura Weihl (IT University of Copenhagen, Denmark)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:20 - 11:45
            </td>
            <td class="title">
                Review on Architectures in the Space Domain to support AI and DevOps: Midterm Findings

            </td>
        </tr>
        <tr>
            <td class="speaker">
                Luciana Rebelo (Gran Sasso Science Institute, Italy)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>  

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:45 - 12:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            <td class="speaker">
              
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table> 

    
    <table>
        <tr>
            <td class="date" rowspan="2">
                12:00 - 13:30
            </td>
            <td class="title-special">
                Lunch
            </td>
        </tr>
        <tr>
            <td class="abstract">
             
            </td>
        </tr>
    </table>
    
     <table>
        <tr>
            <td class="date" rowspan="2">
                13:30 - 15:00 
            </td>
            <td class="title-special">
                Session 6: Robotic Applications 
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>
    
 
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:30 - 13:55
            </td>
            <td class="title">
                From chaos to structure: Unifying software architecture of robots 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Lenka Mudrich (University of Leeds, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                In the rapidly evolving field of robotics, software architecture plays a pivotal role in enabling intelligent behaviour and efficient operation. However, the increasing complexity and heterogeneity of robot systems have led to a proliferation of diverse software architectures, resulting in fragmented development processes and limited interoperability. This talk aims to explore the critical need for software architecture unification in the realm of robotics. I will explore the concept of software architecture unification, which seeks to establish a common framework and set of principles for designing and implementing software architectures in robots. Furthermore, I will discuss the role of modularisation, standardisation, and open-source initiatives in fostering a unified ecosystem. Overall, this talk aims to shed light on the importance of software architecture unification for robots, exploring its benefits, challenges, and potential solutions. By embracing a unified approach, the robotics community can propel the field forward, enabling faster innovation, wider adoption, and more robust and versatile robot systems. 
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:55 - 14:20
            </td>
            <td class="title">
                Runtime reconfiguration of robot control systems
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Davide Brugali (University of Bergamo, Italy)
            </td>
        </tr>
        <tr>
            <td class="abstract">
             </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:20 - 14:45
            </td>
            <td class="title">
                Imitation Learning for creating 3D twin models using a manipulator robot arm
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Juan Antonio Pinera Garcia (Gran Sasso Science Institute, Italy)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Obtaining a precise description of the materials used in ancient art works has proven to be a challenging task, and while progress has been made in employing X-Ray technology to create detailed twin models of two dimensional paintings, 3D objects remain a considerable challenge. This work describes the idea of using Imitation Learning techniques to allow a Human-In-The-Loop algorithm to create high precision models of three dimensional art works. Although the technology exists to be able to determine with high precision the atomic composition of very small segments of an object, the algorithm must automatically detect the different object shapes and perform efficient motion planning in order to cover the object entirely at a desirable distance.

            </td>
        </tr>
    </table>      
    

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:45 - 15:00
            </td>
            <td class="title">
                Discussion
            </td>
        </tr>
        <tr>
            <td class="speaker">
               
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

   <table>
        <tr>
            <td class="date" rowspan="2">
                15:00 - 15:30
            </td>
            <td class="title-special">
                Coffee/Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>

    
    <table>
        <tr>
            <td class="date" rowspan="2">
                15:30 - 17:00
            </td>
            <td class="title-special">
                Break-out rooms, planning collaboration
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                18:30 
            </td>
            <td class="title-special">
                Dinner
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>
    
    <h4>Thursday, September 7</h4>

    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                09:00 - 10:00 

            </td>
            <td class="title">
                TBA
            </td>
        </tr>
        <tr>
            <td class="speaker">
                
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                10:00 - 10:30
            </td>
            <td class="title-special">
                Coffee/Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>

    
    <table>
        <tr>
            <td class="date" rowspan="2">
                10:30 - 12:30
            </td>
            <td class="title-special">
                Session 7: Robotic Applications
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Chair: 
            </td>
        </tr>
    </table>
    
 
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:30 - 10:55
            </td>
            <td class="title">
                 Ethical-aware robots 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Patrizio Pelliccione (Gran Sasso Science Institute, Italy)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:55 - 11:20
            </td>
            <td class="title">
                Enabling Adaptation at Runtime: A Knowledge-Based Framework for Task and Architecture Co-Adaptation in Autonomous Robots
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Gustavo Rezende Silva (TU Delft, The Netherlands)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                While operating, robots are subject to uncertainties, both from internal system factors (e.g., sensor failures) and external environment variables (e.g., different terrains). To overcome uncertainties, robots must be able to adapt at runtime their mission execution (e.g., change task being performed) and their software architecture (e.g., deactivate and activate software components). This presentation introduces a knowledge-based self-adaptation framework designed to enable robots to adapt their mission and architecture at runtime. The proposed framework builds upon the Metacontrol framework, offering a novel contribution in the form of a new metamodel for the knowledge base. The proposed metamodel aims to capture essential information about the robotic system's architecture, encompassing all available configuration variants, relationships and constraints among configurations, attributes of the system and environment, and interdependencies between the robots' tasks and configurations. The metamodel is modeled as a hypergraph, enabling a more intuitive representation of the relationship. To guide the design phase and enable evaluation, we defined a set of requirements for robotic self-adaptive systems. Then, in the evaluation step, we verify if the framework fulfills the defined requirements, and use this assessment as criteria for comparing our approach against other existing self-adaptation frameworks. Furthermore, we showcase the applicability of our framework through its implementation and application to a use case involving an underwater robot deployed for pipeline inspection.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:20 - 11:45
            </td>
            <td class="title">
                Teaching autonomous vehicle engineering 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Thorsten Berger (Ruhr University Bochum, Germany)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>  

    
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:45 - 12:10
            </td>
            <td class="title">
                Robotics Software Engineering in the SESAME H2020 Project
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Simos Gerasimou (University of York, UK)
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table> 

    
    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                12:10 - 12:30
            </td>
            <td class="title">
                Discussion and Closing
            </td>
        </tr>
        <tr>
            <td class="speaker">
              
            </td>
        </tr>
        <tr>
            <td class="abstract">
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                12:30 - 14:00
            </td>
            <td class="title-special">
                Lunch
            </td>
        </tr>
        <tr>
            <td class="abstract">
             
            </td>
        </tr>
    </table>
 
 <footer>
        &copy; Conference Organizers
        &nbsp;|&nbsp; Design by <a href="https://github.com/mikepierce">Mike Pierce</a>
    </footer>

</body>
</html>

